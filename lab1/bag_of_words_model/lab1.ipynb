{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2LYbIEjx1o6S",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8b1fbae6-9370-4397-a9bf-4434aa0aed08",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:12:28.745814327Z",
     "start_time": "2023-11-03T10:12:20.060665569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-sm==3.7.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0-py3-none-any.whl (15.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m15.3/15.3 MB\u001B[0m \u001B[31m8.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m:00:01\u001B[0m0:01\u001B[0mm\r\n",
      "\u001B[?25hRequirement already satisfied: pymorphy3>=1.0.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from ru-core-news-sm==3.7.0) (1.2.1)\r\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from ru-core-news-sm==3.7.0) (3.7.2)\r\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (0.7.2)\r\n",
      "Requirement already satisfied: docopt-ng>=0.6 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (0.9.0)\r\n",
      "Requirement already satisfied: pymorphy3-dicts-ru in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0) (2.4.417150.4580142)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.9)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.5)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (6.4.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.66.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.31.0)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.10)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.9.0)\r\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.3.3)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.2.1)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.26.1)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.1.2)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.4.2)\r\n",
      "Requirement already satisfied: setuptools in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (65.5.1)\r\n",
      "Requirement already satisfied: jinja2 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.1.2)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.10)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (23.2)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.3.0)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.8)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.12)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.10.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.8.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2023.7.22)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.3)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.11)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.1.3)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ALn_QDMnGY7Y",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:12:31.090297445Z",
     "start_time": "2023-11-03T10:12:28.758065616Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2lsjWG-g1o6c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "96da83bb-80b2-409f-bfef-dcd24b6dbd77",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:12:34.033493559Z",
     "start_time": "2023-11-03T10:12:31.096203385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text             label\n",
      "0                                скотина! что сказать          [INSULT]\n",
      "1   я сегодня проезжала по рабочей и между домами ...          [NORMAL]\n",
      "2   очередной лохотрон. зачем придумывать очередно...          [NORMAL]\n",
      "3   ретро дежавю ... сложно понять чужое сердце , ...          [NORMAL]\n",
      "4             а когда мы статус агрогородка получили?          [NORMAL]\n",
      "5   2 августа поздно вечером нашли вот такую потер...          [NORMAL]\n",
      "6         вчера надыбала новые стикеры #u2a94ec7fabs#          [NORMAL]\n",
      "7   заколоть этого плешивого урода что бы крякнул ...  [INSULT, THREAT]\n",
      "8   а еще на стоянке никто не проверяет безопаснос...          [NORMAL]\n",
      "9   красота..!! если есть, что показать??!! почему...          [NORMAL]\n",
      "10                                ходунки какая цена?          [NORMAL]\n",
      "11                      любовь....с первого взгляда..          [NORMAL]\n",
      "12                                ои уже и етому учат          [NORMAL]\n",
      "13  эти скаты ,на героев пионеров, анекдотов навыд...          [NORMAL]\n",
      "14  можно подумать москвичи знают хорошо этого фур...          [NORMAL]\n"
     ]
    }
   ],
   "source": [
    "with open('dataset/toxic_comments.txt', \"r\") as file:\n",
    "    file_readen = file.read().split(\"\\n\")\n",
    "\n",
    "labels = np.array(list(map(lambda x: list(map(lambda y: y[9 :], x.split(\" \")[0].split(\",\"))), file_readen))[: -1], dtype=\"object\")\n",
    "text = list(map(lambda x: \" \".join(x.split(\" \")[1 :]), file_readen))[: -1]\n",
    "\n",
    "df = pd.DataFrame(np.array([text, labels]).T, columns = [\"text\", \"label\"])\n",
    "print(df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KjM9p3jo1o6e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d37cadda-0348-42c2-db44-70188cdd8fd0",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:12:34.077961905Z",
     "start_time": "2023-11-03T10:12:34.018665033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text     label\n",
      "138489                            мало ли что напридумают  [NORMAL]\n",
      "38853   больше никто не требуется . объявлению уже 4 г...  [NORMAL]\n",
      "163377                        такие глаза, ох красавец!!!  [NORMAL]\n",
      "151783                   царанг ту кати тар связь нахтиям  [NORMAL]\n",
      "79986                 вот это мразь, чему радуется козёл.  [INSULT]\n",
      "...                                                   ...       ...\n",
      "117592  ты чудо чудное. ты милый, красивый, дай тебе б...  [NORMAL]\n",
      "213107  пидарок какой-то, ну в смысле, просветлённый, ...  [INSULT]\n",
      "65769                         твои муж дурак из дураков .  [INSULT]\n",
      "86175   владимир кутузов, включите мозги если они у ва...  [NORMAL]\n",
      "71164   у меня таксеныш пока рос сгрыз все и диван нор...  [NORMAL]\n",
      "\n",
      "[124145 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=0.5)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FQsRQ4eS1o6j",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "112a5ca8-eacf-492a-c994-62576b952532",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:12:39.989761248Z",
     "start_time": "2023-11-03T10:12:34.086984900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('мало ли что напридумают', ['NORMAL']), ('больше никто не требуется . объявлению уже 4 года!', ['NORMAL']), ('такие глаза, ох красавец!!!', ['NORMAL']), ('царанг ту кати тар связь нахтиям', ['NORMAL']), ('вот это мразь, чему радуется козёл.', ['INSULT']), ('это апокриф..уже всем известно..так как ранние христиане как и первые о такой библии от варнавы и не слышали и не знали и не читали:-)', ['NORMAL']), ('с днем рождения малыш, здоровья счастья тебе желаю', ['NORMAL']), ('а, что граница открылась?', ['NORMAL']), ('е иbою мать это ж пиздец ееsихпет', ['INSULT']), ('вы тот кем сами себя считаете и видите как правило то, что хотите увидеть. а кто думает, что получая или воруя денег чуть больше чем остальные он свободен, дурак или подлец.', ['INSULT'])]\n"
     ]
    }
   ],
   "source": [
    "data = [tuple(df.iloc[i].values) for i in range(df.shape[0])]\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lKMsUKfV1o6k",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:12:40.157011339Z",
     "start_time": "2023-11-03T10:12:39.941906280Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(data, test_size=0.3, random_state=42, shuffle=True)\n",
    "valid_data, test_data = train_test_split(valid_data, test_size=0.1, random_state=13, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OiCg-Nr2Ga3Z",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:12:40.178372967Z",
     "start_time": "2023-11-03T10:12:40.163110073Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_docs(data):\n",
    "    \"\"\"\n",
    "    this will take a list of texts and labels\n",
    "    and transform them in spacy documents\n",
    "    data: list(tuple(text, label))\n",
    "    returns: List(spacy.Doc.doc)\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    # nlp.pipe([texts]) is way faster than running\n",
    "    # nlp(text) for each text\n",
    "    # as_tuples allows us to pass in a tuple,\n",
    "    # the first one is treated as text\n",
    "    # the second one will get returned as it is.\n",
    "    # a = tqdm(nlp.pipe(data, as_tuples=True), total = len(data))\n",
    "    for doc, labels in tqdm(nlp.pipe(data, as_tuples=True), total = len(data)):\n",
    "        doc.cats = {\"normal\": 0,\n",
    "                    \"insult\": 0,\n",
    "                    \"threat\": 0,\n",
    "                    \"obscenity\": 0}\n",
    "        if 'NORMAL' in labels:\n",
    "          doc.cats[\"normal\"] = 1\n",
    "        if 'INSULT' in labels:\n",
    "          doc.cats[\"insult\"] = 1\n",
    "        if 'THREAT' in labels:\n",
    "          doc.cats[\"threat\"] = 1\n",
    "        if 'OBSCENITY' in labels:\n",
    "          doc.cats[\"obscenity\"] = 1\n",
    "        # we need to set the (text)cat(egory) for each document\n",
    "        #doc.cats[\"positive\"] = label\n",
    "        # put them into a nice list\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ogVuX_fKGdrb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d4913202-b785-4c63-f8af-4c67f13c3e82",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:13:21.753728336Z",
     "start_time": "2023-11-03T10:12:40.176465252Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:41<00:00, 120.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# we are so far only interested in the first 5000 reviews\n",
    "# this will keep the training time short.\n",
    "# In practice take as much data as you can get.\n",
    "# you can always reduce it to make the script even faster.\n",
    "num_texts = 5000\n",
    "# first we need to transform all the training data\n",
    "train_docs = make_docs(train_data[:num_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hL3c5jIJHijB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a3101c6c-3f8f-4b18-a936-4cc8f69041f9",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:14:01.738732897Z",
     "start_time": "2023-11-03T10:13:22.236047695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:38<00:00, 131.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# then we save it in a binary file to disc\n",
    "doc_bin = DocBin(docs=train_docs)\n",
    "doc_bin.to_disk(\"spacy/train.spacy\")\n",
    "# repeat for validation data\n",
    "valid_docs = make_docs(valid_data[:num_texts])\n",
    "doc_bin = DocBin(docs=valid_docs)\n",
    "doc_bin.to_disk(\"spacy/valid.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alCdl9QopLef"
   },
   "source": [
    "на этом месте мы идем в https://spacy.io/usage/training#quickstart, там настраиваем под себя конфиг (textcat), копируем его руками(!) в base_config.cfg, указываем правильные пути до трейн и вэлид\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! touch base_config.cfg"
   ],
   "metadata": {
    "id": "QKQr8JnkcAHt",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:14:01.978083908Z",
     "start_time": "2023-11-03T10:14:01.743021399Z"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "! python -m spacy init fill-config base_config.cfg config.cfg"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQT7xJ6lb6XQ",
    "outputId": "cd8d5a75-5a48-4037-febc-8b163a437a97",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:14:04.104134881Z",
     "start_time": "2023-11-03T10:14:01.984226163Z"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Auto-filled config with all values\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Saved config\u001B[0m\r\n",
      "config.cfg\r\n",
      "You can now add your data and train your pipeline:\r\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! python -m spacy train config.cfg --output ./output --paths.train ./spacy/train.spacy --paths.dev ./spacy/valid.spacy"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0jOR1nRdFYI",
    "outputId": "f4b3f6b9-647c-48be-c2de-08493f4e9f54",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:14:58.800544745Z",
     "start_time": "2023-11-03T10:14:04.108449502Z"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;4mℹ Saving to output directory: output\u001B[0m\r\n",
      "\u001B[38;5;4mℹ Using CPU\u001B[0m\r\n",
      "\u001B[1m\r\n",
      "=========================== Initializing pipeline ===========================\u001B[0m\r\n",
      "\u001B[38;5;2m✔ Initialized pipeline\u001B[0m\r\n",
      "\u001B[1m\r\n",
      "============================= Training pipeline =============================\u001B[0m\r\n",
      "\u001B[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001B[0m\r\n",
      "\u001B[38;5;4mℹ Initial learn rate: 0.001\u001B[0m\r\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \r\n",
      "---  ------  -------------  ----------  ------\r\n",
      "  0       0           0.25       51.76    0.52\r\n",
      "  0     200          32.30       55.48    0.55\r\n",
      "  0     400          21.63       57.02    0.57\r\n",
      "  0     600          20.61       59.31    0.59\r\n",
      "  1     800          17.37       62.46    0.62\r\n",
      "  2    1000          16.00       65.84    0.66\r\n",
      "  2    1200          13.70       69.38    0.69\r\n",
      "\u001B[38;5;3m⚠ Aborting and saving the final best model. Encountered exception:\r\n",
      "FileNotFoundError(2, 'No such file or directory')\u001B[0m\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\r\n",
      "    return _run_code(code, main_globals, None,\r\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/__main__.py\", line 4, in <module>\r\n",
      "    setup_cli()\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/cli/_util.py\", line 87, in setup_cli\r\n",
      "    command(prog_name=COMMAND)\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\r\n",
      "    return self.main(*args, **kwargs)\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/typer/core.py\", line 778, in main\r\n",
      "    return _main(\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/typer/core.py\", line 216, in _main\r\n",
      "    rv = self.invoke(ctx)\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/click/core.py\", line 1688, in invoke\r\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/click/core.py\", line 1434, in invoke\r\n",
      "    return ctx.invoke(self.callback, **ctx.params)\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/click/core.py\", line 783, in invoke\r\n",
      "    return __callback(*args, **kwargs)\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/typer/main.py\", line 683, in wrapper\r\n",
      "    return callback(**use_params)  # type: ignore\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/cli/train.py\", line 54, in train_cli\r\n",
      "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/cli/train.py\", line 84, in train\r\n",
      "    train_nlp(nlp, output_path, use_gpu=use_gpu, stdout=sys.stdout, stderr=sys.stderr)\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/training/loop.py\", line 135, in train\r\n",
      "    raise e\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/training/loop.py\", line 118, in train\r\n",
      "    for batch, info, is_best_checkpoint in training_step_iterator:\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/training/loop.py\", line 243, in train_while_improving\r\n",
      "    score, other_scores = evaluate()\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/training/loop.py\", line 298, in evaluate\r\n",
      "    scores = nlp.evaluate(dev_corpus(nlp))\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/language.py\", line 1435, in evaluate\r\n",
      "    examples = list(examples)\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/training/corpus.py\", line 164, in __call__\r\n",
      "    for real_eg in examples:\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/training/corpus.py\", line 186, in make_examples\r\n",
      "    for reference in reference_docs:\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/training/corpus.py\", line 219, in read_docbin\r\n",
      "    doc_bin = DocBin().from_disk(loc)\r\n",
      "  File \"/home/ilyusha/Desktop/nlp/venv/lib/python3.10/site-packages/spacy/tokens/_serialize.py\", line 275, in from_disk\r\n",
      "    with path.open(\"rb\") as file_:\r\n",
      "  File \"/usr/lib/python3.10/pathlib.py\", line 1119, in open\r\n",
      "    return self._accessor.open(self, mode, buffering, encoding, errors,\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'valid.spacy'\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "j1tnFjeaILJu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "35d02bed-a29c-48ff-fc25-2d8b0d7c6453",
    "ExecuteTime": {
     "end_time": "2023-11-03T10:14:59.407662011Z",
     "start_time": "2023-11-03T10:14:58.808741761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: ребёнок голоден!\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.6493539810180664, 'insult': 0.33670878410339355, 'threat': 0.2311621457338333, 'obscenity': 0.18510280549526215}\n",
      "\n",
      "Sample: и правда! идёшь выносить мусор- а баков нет. зато по пути к бывшей стоянке дорожка из пакетов с мусором. кто мудрит?!\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.9294244647026062, 'insult': 0.042160872370004654, 'threat': 0.0008697120938450098, 'obscenity': 0.00016168357979040593}\n",
      "\n",
      "Sample: хм..., придумают же! 👏\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.760574221611023, 'insult': 0.22027620673179626, 'threat': 0.07510235905647278, 'obscenity': 0.04189739748835564}\n",
      "\n",
      "Sample: дать пожизненный срок и каждый день приходить вкамеру\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.6885133981704712, 'insult': 0.3033641278743744, 'threat': 0.1819431036710739, 'obscenity': 0.1239987388253212}\n",
      "\n",
      "Sample: главное,чтобы она жила\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.6424776911735535, 'insult': 0.32481297850608826, 'threat': 0.17505177855491638, 'obscenity': 0.128448948264122}\n",
      "\n",
      "Sample: дебил себе к башке ствол приставь,так прикольнее будет.\n",
      "Labels: ['INSULT']\n",
      "Output: {'normal': 0.6570304036140442, 'insult': 0.2005535215139389, 'threat': 0.05739980190992355, 'obscenity': 0.026248231530189514}\n",
      "\n",
      "Sample: а при чем здесь тогда собаки. непонятно.\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.705256462097168, 'insult': 0.25355157256126404, 'threat': 0.05327172949910164, 'obscenity': 0.0261574424803257}\n",
      "\n",
      "Sample: с доставкой +50р,устроит?\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.8137310743331909, 'insult': 0.166785329580307, 'threat': 0.06061592698097229, 'obscenity': 0.050084687769412994}\n",
      "\n",
      "Sample: эпифиллум,фото цветения мое\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.692909300327301, 'insult': 0.3168185353279114, 'threat': 0.19188353419303894, 'obscenity': 0.15748776495456696}\n",
      "\n",
      "Sample: у кого как, а у нас была шпилька.\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.7636697292327881, 'insult': 0.22239571809768677, 'threat': 0.018853165209293365, 'obscenity': 0.01202207338064909}\n",
      "\n",
      "Sample: не была не знаю, может быть 😂😂😂\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.7930861711502075, 'insult': 0.16232100129127502, 'threat': 0.028219303116202354, 'obscenity': 0.028244907036423683}\n",
      "\n",
      "Sample: бывает вот такая красота- не передать словами🥰😍\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.797130823135376, 'insult': 0.23401838541030884, 'threat': 0.08213139325380325, 'obscenity': 0.08245276659727097}\n",
      "\n",
      "Sample: хабаровск мы с вами\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.8092653751373291, 'insult': 0.20168866217136383, 'threat': 0.12384086847305298, 'obscenity': 0.11515095829963684}\n",
      "\n",
      "Sample: ложь и предательство убива от четыре правды доброту доверие любовь верность оо\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.7255128026008606, 'insult': 0.30025461316108704, 'threat': 0.12140930444002151, 'obscenity': 0.09809210896492004}\n",
      "\n",
      "Sample: круто-60 тысяч рублей за метр, в день можно сделать метров 10, норм, можно ехать, оплата 10 раз в день, питание не отходя от рабочего места, подставляют горшок для посрать\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.9751723408699036, 'insult': 0.015892380848526955, 'threat': 0.0001580651878612116, 'obscenity': 2.9398179322015494e-05}\n",
      "\n",
      "Sample: постепенно этот культ пьянства уйдет . про международный женский день 8 марта, а по старому 23 февраля отмечают только в 2ух странах в китае и россии. это праздник борьбы женщин за равноправие и пошел он от 2ух парадов проституток организованными 2мя иуд революционерками клары цеткин и розой люксембург. о день вдв спешу поздравить ребят служивших в этих войсках с праздником пожелать кребкого здоровья и быть всегда защитниками справедливости.\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.9656544923782349, 'insult': 0.017234116792678833, 'threat': 3.994680810137652e-06, 'obscenity': 5.694570148762068e-08}\n",
      "\n",
      "Sample: да не надо было ему член показывать, а загнуть суку и вхуярить по самое нехочу.\n",
      "Labels: ['INSULT', 'OBSCENITY']\n",
      "Output: {'normal': 0.5419288277626038, 'insult': 0.2804359197616577, 'threat': 0.023101244121789932, 'obscenity': 0.0021781683899462223}\n",
      "\n",
      "Sample: низкий им поклон от всех живущих!!!\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.5835888981819153, 'insult': 0.257310688495636, 'threat': 0.1049390509724617, 'obscenity': 0.028693441301584244}\n",
      "\n",
      "Sample: сколько процентов окружали сталина евреи вклад армяне не мало положили в рассийскую империю ты прав и микоян также брат еслиб сталина поднять он первых лжи коммунистов растрылял и евреев жидов которые служили еврейскому фашизму германи\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.4983553886413574, 'insult': 0.33652082085609436, 'threat': 0.015894578769803047, 'obscenity': 0.007448531221598387}\n",
      "\n",
      "Sample: если честно, то даже невозможно выделить!\n",
      "Labels: ['NORMAL']\n",
      "Output: {'normal': 0.7315388917922974, 'insult': 0.2564224898815155, 'threat': 0.05846982076764107, 'obscenity': 0.05783150717616081}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# load the best model from training\n",
    "nlp = spacy.load(\"output/model-best\")    \n",
    "for text, labels in test_data[:20]:\n",
    "    doc = nlp(text)\n",
    "    print(f\"Sample: {text}\\nLabels: {labels}\\nOutput: {doc.cats}\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
